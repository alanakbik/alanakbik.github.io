<!DOCTYPE HTML>
<html>

<head>
    <title>Alan Akbik's Homepage</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>

    <!-- Latest compiled Bootstrap -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>

    <!-- Latest compiled and minified CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">

    <link href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css" rel="stylesheet">

</head>


<div class="container">

    <div class="row">

        <div class="col-md-1">
        </div>

        <div class="col-md-10">
            <nav class="navbar navbar-default" role="navigation">
                <div class="grove-nav pull-right hidden-xs visible-sm visible-md visible-lg">
                    <img class="pull-right" src="img/logo-mobile.png" style="max-width:400px; "
                         alt="">
                </div>
                <div class="navbar-collapse grove-nav">
                    <ul class="nav navbar-nav">
                        <li><a href="index.html">Home</a></li>
                        <li><a href="publications.html">Publications</a></li>
                        <li class="active"><a href="flair.html">Flair NLP</a></li>
                        <li><a href="multilingual.html">Universal Proposition Banks</a></li>
                        <li><a href="personal.html">Personal</a></li>
                    </ul>
                </div><!-- /.navbar-collapse -->
            </nav>
            <div class="col-md-9">

                <div>
                    <h2>The Flair NLP Framework</h2>

                    <p><img src="img/flair_logo_2020.svg" alt="A picture of should be here" ALIGN="left" HSPACE="20"
                            VSPACE="20"/></p>

                    <p> My group maintains and develops <a href="https://github.com/flairNLP/flair" target="_blank"><b>Flair</b></a>,
                        an open source framework for state-of-the-art NLP. Flair is an official part of
                        the <a href="https://pytorch.org/ecosystem/" target="_blank"><b>PyTorch ecosystem</b></a>
                        and to-date is used in hundreds of industrial and academic projects.

                        Together with the open source community and Zalando Resarch, my group is
                        are actively developing Flair - and invite you to join us!

                    </p>
                </div>
                <hr/>
                <div >
                    <h4>Research behind Flair</h4>

                    <p> My current research proposes a new approach to address core natural language processing
                        tasks such
                        as part-of-speech (PoS) tagging, named entity recognition (NER), sense disambiguation and
                        text
                        classification. Our approach leverages character-level neural language modeling to learn
                        powerful,
                        contextualized representations of human language from large corpora. The Figure below
                        illustrates
                        how it works:

                    </p></div>
                <div class="row">
                    <div class="col-md-2">
                    </div>
                    <div class="col-md-8">
                        <p>
                            <img src="img/neuralLMtagging.png" alt="A picture of should be here" width="100%"/>
                        </p>
                    </div>
                    <div class="col-md-2">
                    </div>
                </div>
                <p>
                    Here, a sentence (bottom) is input as a character sequence into a bidirectional character
                    language
                    model (LM, yellow in Figure) that was pre-trained on extremely large unlabeled text corpora.
                    From
                    this LM, we retrieve for each word a contextual embedding by extracting the first and last
                    character
                    cell states. This word embedding is then passed into a vanilla BiLSTM-CRF sequence labeler (blue
                    in
                    Figure), achieving robust state-of-the-art results on downstream tasks (NER in this example).
                </p>

                <p>
                    This simple approach works incredibly well. In fact, it <b>outperforms all previous approaches
                    by a
                    significant margin across many classic NLP tasks</b>. Check out some results below:
                </p>
                <table class="table">
                    <thead class="thead-light">
                    <tr>
                        <th scope="col">Task</th>
                        <th scope="col">Dataset</th>
                        <th scope="col">Our Result</th>
                        <th scope="col">Previous best</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr>
                        <td>Named Entity Recognition (English)</td>
                        <td>Conll-03</td>
                        <td><b>93.09</b> (F1)</td>
                        <td>92.22 (Peters et al., 2018)</td>
                    </tr>
                    <tr>
                        <td>Named Entity Recognition (English)</td>
                        <td>Ontonotes</td>
                        <td><b>89.71</b> (F1)</td>
                        <td>86.28 (Chiu et al., 2016)</td>
                    </tr>
                    <tr>
                        <td>Emerging Entity Detection (English)</td>
                        <td>WNUT-17</td>
                        <td><b>50.20</b> (F1)</td>
                        <td>45.55 (Aguilar et al., 2018)</td>
                    </tr>

                    <tr>
                        <td>Named Entity Recognition (German)</td>
                        <td>Conll-03</td>
                        <td><b>88.32</b> (F1)</td>
                        <td>78.76 (Lample et al., 2016)</td>
                    </tr>

                    <tr>
                        <td>Named Entity Recognition (German)</td>
                        <td>Germeval</td>
                        <td><b>84.65</b> (F1)</td>
                        <td>79.08 (Hänig et al, 2014)</td>
                    </tr>

                    <tr>
                        <td>Part-of-Speech tagging (English)</td>
                        <td>WSJ</td>
                        <td><b>97.85</b></td>
                        <td>97.64 (Choi, 2016)</td>
                    </tr>

                    <tr>
                        <td>Chunking (English)</td>
                        <td>Conll-2000</td>
                        <td><b>96.72</b> (F1)</td>
                        <td>96.36 (Peters et al., 2017)</td>
                    </tr>
                    </tbody>
                </table>


                <p>
                    Check out the corresponsing publication for more details:
                </p>
                <p>
                    <b>Contextual String Embeddings for Sequence Labeling. </b>
                    Alan Akbik, Duncan Blythe and Roland Vollgraf.
                    <b><font color="#336699"> 27th International Conference on Computational Linguistics, COLING
                        2018.</font></b>
                    <a href="papers/coling2018.pdf">[pdf]</a>
                </p>
                <hr/>


            </div>


            <div class="col-md-3">
                <img align="middle" src="img/alan.jpg" alt="A picture of me should be here" width="200"/>

                <h3 align="middle">Alan Akbik</h3>
                <p align="middle"><b>Professor of Machine Learning</b><br/>Humbold-Universität zu Berlin<br/>
                    <i>alan [dot] akbik [ät] hu-berlin [dot] de</i></p>
                <div data-include="side"></div>
            </div>


        </div>

        <div class="col-md-1">
        </div>

    </div>
</div>
</body>
</html>
